{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original basic GAN's are very hard to train and inconsistent at producing results. Hence we go through another paper [DCGAN](https://arxiv.org/abs/1511.06434), where they make some architectural constraints for stable and better training.GANs provide an attractive alternative to maximum likelihood techniques. One can additionally argue that their learning process and the lack of a heuristic cost function (such as pixel-wise independent mean-square error) are attractive to representation learning. GANs have been known to be unstable to train, often resulting in generators that produce nonsensical outputs.\n",
    "\n",
    "Paper proposes and evaluates a set of constraints on the architectural topology of Convolutional GANs that make them stable to train in most settings and name this class of architectures Deep Convolutional GANs (DCGAN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historical attempts to scale up GANs using CNNs to model images have been unsuccessful. \n",
    "Paper identifies family of architectures that resulted in stable training across range of datasets\n",
    "and allowed training for higher resolution and deeper generative models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper proposes majorly 3 changes required for better training of GAN's':\n",
    "* Implement fuly convolutional net and replace maxpooling with strided convolutions, allowing the network to learn its own spatial downsampling. They use this approach in generator, allowing it to learn its own spatial upsampling, and discriminator.\n",
    "* Second is the trend towards eliminating fully connected layers on top of convolutional features. The first layer of the GAN, which takes a uniform noise distribution Z as input, could be called fully connected as it is just a matrix multiplication, but the result is reshaped into a 4-dimensional tensor and used as the start of the convolution stack. For the discriminator, the last convolution layer is flattened and then fed into a single sigmoid output.\n",
    "* Third is Batch Normalization which stabilizes learning by normalizing the input to each unit to have zero mean and unit variance.This helps deal with training problems that arise due to poor initialization and helps gradient flow in deeper models. This proved critical to get deep generators to begin learning, preventing the generator from collapsing all samples to a single point which is a common failure mode observed in GANs (**mode collapse**). Directly applying batchnorm to all layers however, resulted in sample oscillation and model instability. This was avoided by not applying batchnorm to the generator output layer and the discriminator input layer. The ReLU activation is used in the generator with the exception of the output layer which uses the Tanh function. We observed that using a bounded activation allowed the model to learn more quickly to saturate and cover the color space of the training distribution. Within the discriminator we found the leaky rectified activation to work well, especially for higher resolution modeling. This is in contrast to the original GAN paper, which used the maxout activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecural Guidelines from the above discussion\n",
    "* Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).\n",
    "* Use batchnorm in both the generator and the discriminator, except the generator output layer and discriminator input layer.\n",
    "* Remove fully connected hidden layers for deeper architectures.\n",
    "* Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
    "* Use LeakyReLU activation in the discriminator for all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.utils as tUtils\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Disriminator(nn.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(Disriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            #input size : nc * H * W\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            # No BatchNorm layer for the input of the Disciminator\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Shape: nf * H/2 * W/2\n",
    "            nn.Conv2d(ndf, ndf *2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Shape: nf*2 * H/4 * W/4\n",
    "            nn.Conv2d(ndf*2, ndf *4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Shape: nf*4 * H/8 * W/8\n",
    "            nn.Conv2d(ndf*4, ndf *8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Shape: nf*8 * H/16 * W/16\n",
    "            nn.Conv2d(ndf*8, 1 , 4, 1, 0, bias=False),\n",
    "            #Shape: 1 * 1 * 1 for H/W = 64\n",
    "            nn.Sigmoid()\n",
    "        )        \n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.main(inp)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            #Input noise: batch_size * Z\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0,bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(True),\n",
    "            #Shape: ngf*8 x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1,bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "            #Shape: ngf*4 x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1,bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            #Shape: ngf*8 x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1,bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            #Shape: ngf*8 x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4,2,1, bias=False),\n",
    "            nn.Tanh()\n",
    "            #Shape: nc * 64 * 64   \n",
    "        )\n",
    "\n",
    "    def forward(self,inp):\n",
    "        return self.main(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc =3; nz = 100; ngf = 64; ndf =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator (\n",
      "  (main): Sequential (\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (11): ReLU (inplace)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = Generator(nz, ngf, nc)\n",
    "netG.apply(weights_init)\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disriminator (\n",
      "  (main): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU (0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU (0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (10): LeakyReLU (0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = Disriminator(nc, ndf)\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_noise(shape):\n",
    "    return torch.randn(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outf = os.getpwd() + '/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, nz ):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images,_) in enumerate(dataloader, 0):\n",
    "            batchsize = images.size[0]\n",
    "            inp = images.cuda()\n",
    "            inpv = Variable(inp)            \n",
    "            real_labels = Variable(torch.ones(batchsize))\n",
    "            \n",
    "            outp = netD(inpv)\n",
    "            errD_real = criterion(outp, real_labels)\n",
    "            errD_real.backward()\n",
    "            D_x = outp.data.mean()\n",
    "            \n",
    "            noise = get_noise((batchsize, nz, 1, 1))\n",
    "            noiseV = Variable(noise)\n",
    "            fake_inp = netG(noiseV)\n",
    "            fake_labels = Variable(torch.zeros(batchsize))\n",
    "            \n",
    "            outp = netD(fake_inp.detach())\n",
    "            errD_fake = criterion(outp, fake_labels)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = outp.data.mean()\n",
    "            \n",
    "            errD = errD_real + errD_fake\n",
    "            optimizerD.step()\n",
    "            \n",
    "            #Update Generator\n",
    "            netG.zero_grad()\n",
    "            labelsv = Variable(torch.ones(batchsize))\n",
    "            outp = netD(fake_inp)\n",
    "            errG = criterion(outp, labelsv)\n",
    "            errG.backward()\n",
    "            D_G_z2 = outp.data.mean()\n",
    "            \n",
    "            optimizerG.step()\n",
    "            \n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, epochs, i, len(dataloader),\n",
    "                 errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))\n",
    "            if i % 100 == 0:\n",
    "                vutils.save_image(inp,\n",
    "                    '%s/real_samples.png' % outf,\n",
    "                    normalize=True)\n",
    "                fake = netG(Variable(get_noise((batchsize, nz, 1, 1))))\n",
    "                vutils.save_image(fake.data,\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
    "                    normalize=True)\n",
    "        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "        torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
